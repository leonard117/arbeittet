%Discounting
Es gibt ein sehr h\"aufiges Problem bei den M-Gramm-Modellen, die aus den Trainingskorpora trainiert werden. Aber die Trainingskorpora sind immer endlich, d. h.  manche m\"ogliche Wortfolgen der L\"ange m werden im Training nicht beobachtet. Ihre Counts sind null und entsprechende M-Gramm-Wahrscheinlichkeiten werden zu null gesch\"atzt. Langer Kontext findet keine Ber\"ucksichtigung. Die Wahrscheinlichkeit f\"ur W\"orter, die im Trainingskorpus nicht nahe beieinander liegen, wird in der Regel untersch\"atzt.
Um das Problem zu l\"osen setzt man ein sog. Gl\"attungsverfahren ein, das ungesehen Wortfolgen eine nicht-verschwindenden Wahrscheinlichkeit zuordnete. Diese zu ungesehen Ereignissen zugeordnet Wahrscheinlichkeit wird h\"aufig gesehenen Ereignissen abgezogen.
