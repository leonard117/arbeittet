%add_one_smoothing
Das Add-One Discounting liefert andere L\"osung des Zero-Wahrscheinlichkeits-Problems. Man berechnet den ML-Sch\"atzwert aus Gleichung (2.8). In der Add-One-Methode addiert man Eins zu allen Zahle der W\"orter (oder m-Gramm) vor dem Norminierungsverfahren.  Und die Gleichung (2.8) wird durch (2.14) ersetzt.

%2.14
\begin{equation}
\label{equation:add_one_01}
p^{*}(w_{n}|w_{n-m+1}^{n-1})=\frac{c(w_{n},w_{n-m+1}^{n-1})+1}{c(w_{n-m+1}^{n-1})+V}=\frac{c_{k}^{*}}{N+V}
\end{equation}

Hier $V$ ist Vokabulargr??e (oder gesamt Anzahl der m-Gramm-Typen) , damit \\ 
$\sum{w_{n}}p^{*}(w_{n}|w_{n-m+1}^{n-1})=1$

Nach diesem Verfahren wird die Wahrscheinlichkeit aller angesehenen W?rter relativ geringer. Und die alle W\"orter mit Null-Wahrscheinlichkeit bekommen eine gleiche neue Sch\"atzwert $\frac{1}{N+V}$. Zusammenfassung ist
%2.15
\begin{equation}
p^{*}(w_{n}|w_{n-m+1}^{n-1})=\begin{cases}
\frac{c(w_{n},w_{n-m+1}^{n-1})+1}{N+V} & c(w_{n},w_{n-m+1}^{n-1})>0 \\
\frac{1}{N+V} & c(w_{n},w_{n-m+1}^{n-1})=0 
\end{cases}
\end{equation}

Add-One-Discounting ist ein sehr einfache Algorithmus und funktioniert nicht so gut, weil die Wahrscheinlichkeitsma\ss der "Nonzero"-m-GramM nach diesem Verfahren sehr viel ge\"andert werden\cite{book_speech}. Folglich ist Add-One-Discounting  praktisch kaum verwendet.