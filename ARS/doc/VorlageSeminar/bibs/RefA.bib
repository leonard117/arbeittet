% This file was created with JabRef 2.3.1.
% Encoding: UTF-8

@ARTICLE{Alspach1972c,
  author = {Alspach, D. and Alspach, D. and Sorenson, H.},
  title = {Nonlinear Bayesian estimation using Gaussian sum approximations},
  journal = IEEE_J_AC,
  year = {1972},
  volume = {17},
  pages = {439--448},
  number = {4},
  editor = {Sorenson, H.},
  file = {:home/leutnant/jabref/papers/asr/Alspach1972c.pdf:PDF},
  issn = {0018-9286},
  keywords = {Approximation methods, Bayes procedures, Nonlinear estimation, Nonlinear
	systems, stochastic discrete-time, State estimation},
  owner = {leutnant},
  timestamp = {2008.03.13}
}

@ARTICLE{Digalakis1993,
  author = {Digalakis, V. and Rohlicek, J.R. and Ostendorf, M.},
  title = {ML estimation of a stochastic linear system with the EM algorithm
	and its application to speech recognition},
  journal = IEEE_J_SAP,
  year = {1993},
  volume = {1},
  pages = {431--442},
  number = {4},
  month = {Oct. },
  doi = {10.1109/89.242489},
  file = {:home/leutnant/jabref/papers/asr/Digalakis1993.pdf:PDF},
  owner = {leutnant},
  timestamp = {2008.02.01}
}

@INPROCEEDINGS{Droppo2004,
  author = {Droppo, Jasha and Acero, Alex},
  title = {Noise Robust Speech Recognition with a Switching Linear Dynamic Model},
  booktitle = {Proc. IEEE International Conference on Acoustics, Speech, and Signal
	Processing (ICASSP '04)},
  year = {2004},
  editor = {Acero, Alex},
  volume = {1},
  pages = {I--953-6 vol.1},
  abstract = {Model based feature enhancement techniques are constructed from acoustic
	models for speech and noise, together with a model of how the speech
	and noise produce the noisy observations. Most techniques incorporate
	either Gaussian mixture models (GMM) or hidden Markov models (HMM).
	This paper explores using a switching linear dynamic model (LDM)
	for the clean speech. The linear dynamics of the model capture the
	smooth time evolution of speech. The switching states of the model
	capture the piecewise stationary characteristics of speech. However,
	incorporating a switching LDM causes the enhancement problem to become
	intractable. With a GMM or an HMM, the enhancement running time is
	proportional to the length of the utterance. The switching LDM causes
	the running time to become exponential in the length of the utterance.
	To overcome this drawback, the standard generalized pseudo-Bayesian
	technique is used to provide an approximate solution of the enhancement
	problem. We present preliminary results demonstrating that, even
	with relatively small model sizes, substantial word error rate improvement
	can be achieved.},
  doi = {10.1109/ICASSP.2004.1326145},
  file = {:home/leutnant/jabref/papers/asr/Droppo2004.pdf:PDF},
  issn = {1520-6149},
  keywords = {Bayes methods, error statistics, feature extraction, speech enhancement,
	speech recognition, acoustic models, approximate solution, automatic
	speech recognition systems, exponential running time, generalized
	pseudo-Bayesian technique GPB, moment matching, model based feature
	enhancement, noise robust speech recognition, piecewise stationary
	characteristics, smooth time evolution, speech enhancement, switching
	linear dynamic model, word error rate improvement},
  owner = {leutnant},
  timestamp = {2008.01.31}
}

@INPROCEEDINGS{Droppo2002,
  author = {Droppo, J. and Droppo, J. and Acero, A. and Deng, Li},
  title = {Uncertainty decoding with SPLICE for noise robust speech recognition},
  booktitle = {Proc. IEEE International Conference on Acoustics, Speech, and Signal
	Processing (ICASSP '02)},
  year = {2002},
  editor = {Acero, A.},
  volume = {1},
  pages = {I-57--I-60 vol.1},
  abstract = {Speech recognition front end noise removal algorithms have, in the
	past, estimated clean speech features from corrupted speech features.
	The accuracy of the noise removal process varies from frame to frame,
	and from dimension to dimension in the feature stream, due in part
	to the instantaneous SR of the input. In this paper, we show that
	localized knowledge of the accuracy of the noise removal process
	can be directly incorporated into the Gaussian evaluation within
	the decoder, to produce higher recognition accuracies. To prove this
	concept, we modify the SPLICE algorithm to output uncertainty information,
	and show that the combination of SPLICE with uncertainty decoding
	can remove 74.2% of the errors in a subset of the Aurora2 task.},
  doi = {10.1109/ICASSP.2002.1005674},
  file = {:home/leutnant/jabref/papers/asr/Acero2002.pdf:PDF},
  issn = {1520-6149},
  keywords = {Gaussian noise, decoding, probability, speech coding, speech recognition,
	uncertainty handling, Aurora2 task, Gaussian evaluation, SPLICE algorithm,
	front end noise removal algorithms, localized accuracy knowledge,
	robust speech recognition, uncertainty decoding},
  owner = {leutnant},
  timestamp = {2008.03.18}
}

@PHDTHESIS{Frankel2003phd,
  author = {Frankel, Joe},
  title = {Linear Dynamic Models For Automatic Speech Recognition},
  school = {University of Edinburgh},
  year = {2003},
  file = {:home/leutnant/jabref/papers/asr/Frankel2003_phdthesis.pdf:PDF},
  owner = {leutnant},
  timestamp = {2008.02.01}
}

@ARTICLE{Frankel2007,
  author = {Frankel, Joe and King, Simon},
  title = {Speech Recognition Using Linear Dynamic Models},
  journal = {IEEE Transactions on Audio, Speech, and Language Processing},
  year = {2007},
  volume = {15},
  pages = {246--256},
  number = {1},
  abstract = {The majority of automatic speech recognition systems rely on hidden
	Markov models, in which Gaussian mixtures model the output distributions
	associated with sub-phone states. This approach, whilst successful,
	models consecutive feature vectors (augmented to include derivative
	information) as statistically independent. Furthermore, spatial correlations
	present in speech parameters are frequently ignored through the use
	of diagonal covariance matrices. This paper continues the work of
	Digalakis and others who proposed instead a first-order linear state-space
	model which has the capacity to model underlying dynamics, and furthermore
	give a model of spatial correlations. This paper examines the assumptions
	made in applying such a model and shows that the addition of a hidden
	dynamic state leads to increases in accuracy over otherwise equivalent
	static models. We also propose a time-asynchronous decoding strategy
	suited to recognition with segment models. We describe implementation
	of decoding for linear dynamic models and present TIMIT phone recognition
	results},
  doi = {10.1109/TASL.2006.876766},
  editor = {King, Simon},
  file = {:home/leutnant/jabref/papers/asr/Frankel2007.pdf:PDF},
  issn = {1558-7916},
  keywords = {Gaussian processes, covariance matrices, decoding, hidden Markov models,
	speech coding, speech recognition, Gaussian mixtures model, automatic
	speech recognition, diagonal covariance matrices, equivalent static
	models, hidden Markov models, linear dynamic models, spatial correlations,
	time-asynchronous decoding strategy, Automatic speech recognition
	(ASR), linear dynamic models (LDMs), stack decoding},
  owner = {leutnant},
  timestamp = {2008.01.31}
}

@ARTICLE{Frey2001,
  author = {Frey, Brendan J. and Deng, Li and Acero, Alex and Kristjansson, Trausti},
  title = {ALGONQUIN: iterating laplace's method to remove multiple types of
	acoustic distortion for robust speech recognition},
  journal = {EUROSPEECH 2001},
  year = {2001},
  volume = {?},
  pages = {901-904},
  abstract = {We show how an iterative form of Laplace's method can be used to estimate
	the log-spectrum of clean speech from the log-spectrum of noisy,
	distorted speech, using a time-varying mixture model of the logspectra
	of the clean speech, noise, channel distortion and noisy speech.
	We use this method, called ALGONQUIN, to denoise speech features
	and then feed these features into a large vocabulary speech recognizer
	whose WER on the clean WSJ data is 4.9%. When 10dB of time-varying
	airplane engine noise is added to the data, the recognizer obtains
	a WER of 28.8%. ALGONQUIN reduces the WER to 12.6%, well below the
	WER of 25.0% obtained by spectral subtraction, and close to the WER
	of 9.7% obtained by retraining the recognizer on training data corrupted
	by the exact same noise. If ALGONQUIN is used to denoise the noisy
	training data before the recognizer is retrained, the WER drops to
	8.5%. For 10dB of white noise, spectral subtraction reduces the WER
	from 55.1% to 33.8%. ALGONQUIN reduces the WER to 14.2%. The recognizer
	trained on noisy data obtains a WER of 14.0%, whereas the recognizer
	trained on noisy data denoised by ALGONQUIN obtains a WER of 9.9%.},
  file = {:home/leutnant/jabref/papers/asr/Frey2001.pdf:PDF},
  keywords = {ALGONQUINE},
  owner = {leutnant},
  timestamp = {2008.03.13}
}

@PHDTHESIS{Gales1995phd,
  author = {Gales, M.J.F.},
  title = {Model-based techniques for noise robust speech recognition},
  school = {Gonville and Caius College},
  year = {1995},
  file = {:home/leutnant/jabref/papers/asr/Gales1995_phdthesis.pdf:PDF},
  owner = {leutnant},
  timestamp = {2008.03.17}
}

@ARTICLE{Kim2005,
  author = {Kim, Nam Soo and Lim, Woohyung and Stern, R.M.},
  title = {Feature compensation based on switching linear dynamic model},
  journal = IEEE_J_SPL,
  year = {2005},
  volume = {12},
  pages = {473--476},
  number = {6},
  abstract = {In this letter, we propose a novel approach to feature compensation
	for robust speech recognition in noisy environments. We employ the
	switching linear dynamic model (SLDM) as a parametric model for the
	clean speech distribution, which enables us to exploit temporal correlations
	inherent in speech signals. Both the background noise and clean speech
	components are simultaneously estimated by means of the interacting
	multiple model (IMM) algorithm.},
  doi = {10.1109/LSP.2005.847862},
  editor = {Lim, Woohyung},
  file = {:home/leutnant/jabref/papers/asr/Kim2005.pdf:PDF},
  issn = {1070-9908},
  keywords = {correlation theory, speech recognition, IMM algorithm, SLDM, clean
	speech component, feature compensation, interacting multiple model,
	noisy environment, speech recognition, switching linear dynamic model,
	Feature compensation, robust speech recognition, switching linear
	dynamic model (SLDM)},
  owner = {leutnant},
  timestamp = {2008.03.10}
}

@INPROCEEDINGS{Liao2006,
  author = {Liao, H. and Gales, M.J.F.},
  title = {Issues with uncertainty decoding in noise robust speech recognition},
  booktitle = {Interspeech},
  year = {2006},
  series = {Proceedings Interspeech},
  abstract = {Recently there has been interest in uncertainty decoding for robust
	speech recognition. Here the uncertainty associated with the observation
	in noise is propagated to the recogniser. By usingappropriate approximations
	for this uncertainty, it is possible to obtain efficient implementations
	during decoding. The aim of these schemes is to obtain performance
	which is close to that of amodel-based compensated system, without
	the computational cost. Unfortunately, in low SNR there is a fundamental
	issue with front-end uncertainty decoding where the model means and
	variances are updated according to the features. This is described
	in detail using the Joint and SPLICE with uncertainty forms, but
	is not limited to these two techniques. A solution for the Joint
	scheme ispresented along with the implicit approach used in SPLICE
	with uncertainty. In addition, a model-based Joint uncertainty scheme
	is described, which is more efficient and powerful than the front-end
	schemes, and being model-based not affected by this problem. This
	issue is illustrated using the AURORA 2.0 database with these various
	systems.},
  file = {:home/leutnant/jabref/papers/asr/Liao2005.pdf:PDF},
  journal = {Interspeech},
  owner = {leutnant},
  timestamp = {2008.03.10}
}

@PHDTHESIS{Moreno1996phd,
  author = {Moreno, Pedro J.},
  title = {Speech Recognition in Noisy Environments},
  school = {Carnegie Mellon University},
  year = {1996},
  file = {:home/leutnant/jabref/papers/asr/Moreno1996_phdthesis.pdf:PDF},
  owner = {leutnant},
  timestamp = {2008.02.01}
}

@ARTICLE{Rauch1963,
  author = {Rauch, H.},
  title = {Solutions to the Linear Smoothing Problem},
  journal = IEEE_J_AC,
  year = {1963},
  volume = {8},
  pages = {371--372},
  number = {4},
  file = {:home/leutnant/jabref/papers/asr/Rauch1963.pdf:PDF},
  issn = {0018-9286},
  keywords = {Linear systems, time-varying discrete-time, Smoothing methods},
  owner = {leutnant},
  timestamp = {2008.01.31}
}

@PHDTHESIS{Wessel2002phd,
  author = {Wessel, Frank},
  title = {Word Posterior Probabilities for Large Vocabulary Continuous Speech
	Recognition},
  school = {RWTH Aachen},
  year = {2002},
  file = {:home/leutnant/jabref/papers/asr/Wessel2002_phdthesis.pdf:PDF},
  owner = {leutnant},
  timestamp = {2008.03.31}
}

@PHDTHESIS{Windmann2008phd,
  author = {Windmann, Stefan},
  title = {Ausnutzung von Inter-Frame Korrelationen in der automatischen Spracherkennung},
  school = {University of Paderborn},
  year = {2008},
  file = {:home/leutnant/Desktop/DFG_ASR/OwnPapers/Diss_StefanWindmann.pdf:PDF},
  owner = {leutnant},
  timestamp = {2008.03.17}
}

@comment{jabref-meta: selector_publisher:}

@comment{jabref-meta: selector_author:}

@comment{jabref-meta: selector_journal:}

@comment{jabref-meta: selector_keywords:}

